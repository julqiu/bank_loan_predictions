{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dcbb703",
   "metadata": {},
   "source": [
    "# Final Kaggle Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21a2706f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score,train_test_split\n",
    "from sklearn.metrics import mean_squared_error,r2_score,roc_curve,auc\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeRegressor,DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, ParameterGrid\n",
    "from sklearn.ensemble import BaggingRegressor,BaggingClassifier,RandomForestRegressor,RandomForestClassifier,AdaBoostRegressor,AdaBoostClassifier, StackingRegressor, StackingClassifier\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import itertools as it\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "\n",
    "#Libraries for visualizing trees\n",
    "from sklearn.tree import export_graphviz \n",
    "from six import StringIO\n",
    "from IPython.display import Image  \n",
    "import pydotplus\n",
    "\n",
    "# Linear Regression Libraries\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.linear_model import Ridge, RidgeCV, Lasso, LassoCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# MARS\n",
    "from pyearth import Earth\n",
    "import time as time\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import VotingRegressor, VotingClassifier, StackingRegressor, StackingClassifier, GradientBoostingRegressor,GradientBoostingClassifier, BaggingRegressor,BaggingClassifier,RandomForestRegressor,RandomForestClassifier,AdaBoostRegressor,AdaBoostClassifier\n",
    "\n",
    "\n",
    "np.warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1f849f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original data\n",
    "data = pd.read_csv('train.csv')\n",
    "validation_data = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf1cdff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data cleaning\n",
    "state_freqs = data.addr_state.value_counts().to_frame().reset_index().rename(columns={'index' : \"state\", \"addr_state\" : \"count\"})\n",
    "other_state = state_freqs[state_freqs['count'] < data.shape[0] * .01]['state'].tolist()\n",
    "\n",
    "def clean(data):\n",
    "    \n",
    "    df = data.copy()\n",
    "    # addr_state: 'other' category\n",
    "    for obs in range(df.shape[0]):\n",
    "        if df.loc[obs, 'addr_state'] in other_state:\n",
    "            df.loc[obs, 'addr_state'] = 'Other'\n",
    "            \n",
    "    # earliest_cr_line: split month, year\n",
    "    df['earliest_cr_line_month'] = df.earliest_cr_line.str.split('-', expand = True)[0]\n",
    "    df['earliest_cr_line_year'] = df.earliest_cr_line.str.split('-', expand = True)[1].astype(int)\n",
    "    df.drop(columns = ['earliest_cr_line'], inplace = True)\n",
    "    \n",
    "    # last_credit_pull_d: split month, year\n",
    "    df['last_credit_pull_d_month'] = df.last_credit_pull_d.str.split('-', expand = True)[0]\n",
    "    df['last_credit_pull_d_year'] = df.last_credit_pull_d.str.split('-', expand = True)[1].astype(int)\n",
    "    df.drop(columns = 'last_credit_pull_d', inplace = True)\n",
    "    \n",
    "    # sub_grade: remove numeric ratings, group F and G into 'other'\n",
    "    df['sub_grade_letter'] = df['sub_grade'].str.extract('([A-Z]+)')\n",
    "    df.loc[df[\"sub_grade_letter\"] == \"F\", \"sub_grade_letter\"] = \"Other\"\n",
    "    df.loc[df[\"sub_grade_letter\"] == \"G\", \"sub_grade_letter\"] = \"Other\"\n",
    "    df.drop(columns = 'sub_grade', inplace = True)\n",
    "    \n",
    "    # drop 'id' columns\n",
    "    df.drop(columns = 'id', inplace = True)\n",
    "    \n",
    "    return df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40a53f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = clean(data) # train \n",
    "test = clean(validation_data) # kaggle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "231d61d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for predictors\n",
    "X = train.drop(columns = ['money_made_inv'])\n",
    "# filter for response\n",
    "y = train['money_made_inv']\n",
    "\n",
    "# 70% of training data becomes the new train set, 30% becomes new test set\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, train_size = int(train.shape[0]*.7), random_state = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b33889b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numeric predictors\n",
    "Xtrain_num = Xtrain.select_dtypes(include=np.number)\n",
    "Xtest_num = Xtest.select_dtypes(include=np.number)\n",
    "\n",
    "# categorical predictors\n",
    "Xtrain_cat = Xtrain[['sub_grade_letter', 'term', 'initial_list_status', 'application_type']]\n",
    "Xtest_cat = Xtest[['sub_grade_letter', 'term', 'initial_list_status', 'application_type']]\n",
    "\n",
    "# numeric and categorical predictors\n",
    "Xtrain_num_cat = pd.concat([Xtrain_num, pd.get_dummies(Xtrain_cat)],axis=1)\n",
    "Xtest_num_cat = pd.concat([Xtest_num, pd.get_dummies(Xtest_cat)],axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf65200",
   "metadata": {},
   "source": [
    "## XGB Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9511bdfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 180 candidates, totalling 900 fits\n",
      "Optimal parameter values = {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 1000, 'reg_lambda': 0.001}\n",
      "Optimal cross validation R-squared =  0.9910258596256222\n",
      "Time taken =  57.10975794792175  minutes\n"
     ]
    }
   ],
   "source": [
    "#K-fold cross validation to find optimal parameters for XGBoost\n",
    "\n",
    "start_time = time.time()\n",
    "param_grid = {'max_depth': [3,4,5],\n",
    "              'learning_rate': [0.01,0.05,0.1,0.2],\n",
    "               'reg_lambda':[0,0.01,0.001],\n",
    "                'n_estimators':[150,175,250,500,1000]}\n",
    "\n",
    "cv = KFold(n_splits=5,shuffle=True,random_state=1)\n",
    "optimal_params = GridSearchCV(estimator=xgb.XGBRegressor(random_state=1),                                                       \n",
    "                             param_grid = param_grid,                             \n",
    "                             verbose = 1,\n",
    "                             n_jobs=-1,\n",
    "                             cv = cv)\n",
    "\n",
    "optimal_params.fit(Xtrain_num_cat, ytrain)\n",
    "print(\"Optimal parameter values =\", optimal_params.best_params_)\n",
    "print(\"Optimal cross validation R-squared = \",optimal_params.best_score_)\n",
    "print(\"Time taken = \", (time.time()-start_time)/60, \" minutes\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "adec9e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_reg_lambda</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>55.065593</td>\n",
       "      <td>0.175879</td>\n",
       "      <td>0.018372</td>\n",
       "      <td>0.002253</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 4, 'n_esti...</td>\n",
       "      <td>0.993847</td>\n",
       "      <td>0.995490</td>\n",
       "      <td>0.989534</td>\n",
       "      <td>0.991368</td>\n",
       "      <td>0.984890</td>\n",
       "      <td>0.991026</td>\n",
       "      <td>0.003684</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>71.154357</td>\n",
       "      <td>0.512047</td>\n",
       "      <td>0.021180</td>\n",
       "      <td>0.004873</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>0.992719</td>\n",
       "      <td>0.995576</td>\n",
       "      <td>0.989321</td>\n",
       "      <td>0.991544</td>\n",
       "      <td>0.985781</td>\n",
       "      <td>0.990988</td>\n",
       "      <td>0.003294</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>67.723359</td>\n",
       "      <td>0.319800</td>\n",
       "      <td>0.020447</td>\n",
       "      <td>0.004498</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.993041</td>\n",
       "      <td>0.995519</td>\n",
       "      <td>0.989604</td>\n",
       "      <td>0.991143</td>\n",
       "      <td>0.985379</td>\n",
       "      <td>0.990937</td>\n",
       "      <td>0.003410</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>67.542800</td>\n",
       "      <td>0.377078</td>\n",
       "      <td>0.019593</td>\n",
       "      <td>0.002623</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>0.992829</td>\n",
       "      <td>0.995603</td>\n",
       "      <td>0.989247</td>\n",
       "      <td>0.991781</td>\n",
       "      <td>0.985169</td>\n",
       "      <td>0.990926</td>\n",
       "      <td>0.003527</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>33.079133</td>\n",
       "      <td>0.797477</td>\n",
       "      <td>0.016345</td>\n",
       "      <td>0.003737</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.993032</td>\n",
       "      <td>0.995495</td>\n",
       "      <td>0.989526</td>\n",
       "      <td>0.991110</td>\n",
       "      <td>0.985353</td>\n",
       "      <td>0.990903</td>\n",
       "      <td>0.003417</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "119      55.065593      0.175879         0.018372        0.002253   \n",
       "87       71.154357      0.512047         0.021180        0.004873   \n",
       "132      67.723359      0.319800         0.020447        0.004498   \n",
       "89       67.542800      0.377078         0.019593        0.002623   \n",
       "129      33.079133      0.797477         0.016345        0.003737   \n",
       "\n",
       "    param_learning_rate param_max_depth param_n_estimators param_reg_lambda  \\\n",
       "119                 0.1               4               1000            0.001   \n",
       "87                 0.05               5               1000                0   \n",
       "132                 0.1               5               1000                0   \n",
       "89                 0.05               5               1000            0.001   \n",
       "129                 0.1               5                500                0   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "119  {'learning_rate': 0.1, 'max_depth': 4, 'n_esti...           0.993847   \n",
       "87   {'learning_rate': 0.05, 'max_depth': 5, 'n_est...           0.992719   \n",
       "132  {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...           0.993041   \n",
       "89   {'learning_rate': 0.05, 'max_depth': 5, 'n_est...           0.992829   \n",
       "129  {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...           0.993032   \n",
       "\n",
       "     split1_test_score  split2_test_score  split3_test_score  \\\n",
       "119           0.995490           0.989534           0.991368   \n",
       "87            0.995576           0.989321           0.991544   \n",
       "132           0.995519           0.989604           0.991143   \n",
       "89            0.995603           0.989247           0.991781   \n",
       "129           0.995495           0.989526           0.991110   \n",
       "\n",
       "     split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "119           0.984890         0.991026        0.003684                1  \n",
       "87            0.985781         0.990988        0.003294                2  \n",
       "132           0.985379         0.990937        0.003410                3  \n",
       "89            0.985169         0.990926        0.003527                4  \n",
       "129           0.985353         0.990903        0.003417                5  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = pd.DataFrame(optimal_params.cv_results_)\n",
    "cv_results.sort_values(by = 'mean_test_score', ascending = False).head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05d3037",
   "metadata": {},
   "source": [
    "n trees -- flattens out beyond 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "966a302f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "             gamma=0, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.1, max_delta_step=0,\n",
       "             max_depth=4, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=1000, n_jobs=8,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=1, reg_alpha=0,\n",
       "             reg_lambda=0.001, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  result from hour-long tuning \n",
    "# learning_rate : 0.1, 'max_depth': 4, 'n_estimators': 1000, 'reg_lambda': 0.001\n",
    "\n",
    "model_xgb = xgb.XGBRegressor(random_state=1,max_depth=4,\n",
    "                             n_estimators=1000, learning_rate = 0.1,\n",
    "                             reg_lambda= 0.001)\n",
    "\n",
    "model_xgb.fit(Xtrain_num_cat, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c72d0ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "632.7679326915154"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 632??\n",
    "pred_xgb = model_xgb.predict(Xtest_num_cat)\n",
    "np.sqrt(mean_squared_error(pred_xgb,ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36bb828b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "             gamma=0, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.05, max_delta_step=0,\n",
       "             max_depth=5, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=1000, n_jobs=8,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=1, reg_alpha=0,\n",
       "             reg_lambda=0.001, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb = xgb.XGBRegressor(random_state=1,max_depth=5,\n",
    "                             n_estimators=1000, learning_rate = 0.05,\n",
    "                             reg_lambda= 0.001)\n",
    "\n",
    "model_xgb.fit(Xtrain_num_cat, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a80d7c40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "673.0934735658578"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_xgb = model_xgb.predict(Xtest_num_cat)\n",
    "np.sqrt(mean_squared_error(pred_xgb,ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01372856",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a291d1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60712df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57575bc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72782b07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd499d54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "             gamma=0, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.05, max_delta_step=0,\n",
       "             max_depth=6, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=250, n_jobs=8,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=1, reg_alpha=0,\n",
       "             reg_lambda=0, scale_pos_weight=1, subsample=1, tree_method='exact',\n",
       "             validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb = xgb.XGBRegressor(random_state=1,max_depth=6,n_estimators=250,\n",
    "                                         learning_rate = 0.05,reg_lambda= 0)\n",
    "\n",
    "model_xgb.fit(Xtrain_num_cat, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32688a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "750.2334694688906"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_xgb = model_xgb.predict(Xtest_num_cat)\n",
    "np.sqrt(mean_squared_error(pred_xgb,ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf56d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351caff8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3729fbe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9688eb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bf4252",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ead52be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
